{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "h2muJw9NCCRN"
      },
      "outputs": [],
      "source": [
        "#GAN architecture\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras as ke\n",
        "LR_shape = (32,32,3)\n",
        "s = 2\n",
        "HR_shape = (LR_shape[0]*s,LR_shape[1]*s,3)\n",
        "\n",
        "\n",
        "def Generator(LR_shape = LR_shape,s = s):\n",
        "    model = ke.Sequential()\n",
        "    # model.add(ke.layers.Conv2D(3,(64,64),strides=(4,4),input_shape=LR_shape,activation='relu'))\n",
        "    # model.add(ke.layers.MaxPool2D())\n",
        "    model.add(ke.layers.Flatten(input_shape=(LR_shape)))\n",
        "    model.add(ke.layers.Dense(LR_shape[0]*s*LR_shape[1]*s*3,activation='sigmoid'))\n",
        "    HR_shape = (LR_shape[0]*s,LR_shape[1]*s,3)\n",
        "    model.add(ke.layers.Reshape(HR_shape))\n",
        "    return model\n",
        "\n",
        "def Discriminator(HR_shape = (LR_shape[0]*s,LR_shape[1]*s,3)):\n",
        "    model = ke.Sequential()\n",
        "    # model.add(ke.layers.Conv2D(3,(64,64),input_shape = (1024,1024,3),activation='relu'))\n",
        "    # model.add(ke.layers.MaxPool2D())\n",
        "    model.add(ke.layers.Flatten(input_shape=HR_shape))\n",
        "    model.add(ke.layers.Dense(500,activation='relu'))\n",
        "    model.add(ke.layers.Dense(100,activation='relu'))\n",
        "    model.add(ke.layers.Dense(1,activation='sigmoid'))\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# drive access\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "21zDbM8hCOqp",
        "outputId": "77f41ec9-2cb8-4b85-bcd3-fb6613dd07c5"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# making low res images\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import numpy\n",
        "\n",
        "def get_img_arr(path: str):\n",
        "    img = np.array(Image.open(path))\n",
        "    return img\n",
        "\n",
        "def high_to_lowres(img_num: str):\n",
        "    img_path = \"/content/gdrive/MyDrive/00000/\"+img_num+\".png\" #replace with location of data\n",
        "    img_arr = get_img_arr(img_path)\n",
        "    img_arr = img_arr.astype(np.float64)\n",
        "    lr_img_arr = np.zeros((512,512,3))\n",
        "    for k in range(lr_img_arr.shape[2]):\n",
        "        for i in range(lr_img_arr.shape[0]):\n",
        "            for j in range(lr_img_arr.shape[1]):\n",
        "                lr_img_arr[i,j,k] = (img_arr[2*i,2*j,k] + img_arr[2*i,2*j+1,k] + img_arr[2*i+1,2*j,k] + img_arr[2*i+1,2*j+1,k])/4\n",
        "    lr_img = Image.fromarray(lr_img_arr.astype(np.uint8))\n",
        "    lr_img.save(\"/content/gdrive/MyDrive/lr_imgs/\"+img_num+\"_lr.png\") #replace with desired location of LR images\n",
        "\n",
        "img_num = '00000'\n",
        "img0 = get_img_arr(\"/content/gdrive/MyDrive/00000/\"+img_num+\".png\") #replace with location of data\n",
        "img0.shape"
      ],
      "metadata": {
        "id": "wYN2HYcSCYmw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "68ed578d-9676-4364-f4e7-42d74e548cc4"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1024, 1024, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# apply above high_to_lowres function on '00000' to '01000'\n",
        "\n",
        "for i in range(0,1000):\n",
        "    img_num = str(i).zfill(5)\n",
        "    high_to_lowres(img_num)\n"
      ],
      "metadata": {
        "id": "IuFws-YKCgPh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model creation\n",
        "\n",
        "combined_gan = ke.Sequential()\n",
        "\n",
        "gen = Generator()\n",
        "gen.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])\n",
        "combined_gan.add(gen)\n",
        "disc = Discriminator()\n",
        "disc.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])\n",
        "disc.trainable = False\n",
        "combined_gan.add(disc)\n",
        "combined_gan.compile(loss='mse', optimizer='adam', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "SsuuF6roVrZd"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "disc.summary()\n",
        "gen.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GN3NGwoeP5Ut",
        "outputId": "df64e774-5281-4881-bca0-451ad2c555ac"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_3 (Flatten)         (None, 12288)             0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 500)               6144500   \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 100)               50100     \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 1)                 101       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 6194701 (23.63 MB)\n",
            "Trainable params: 0 (0.00 Byte)\n",
            "Non-trainable params: 6194701 (23.63 MB)\n",
            "_________________________________________________________________\n",
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_2 (Flatten)         (None, 3072)              0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 12288)             37761024  \n",
            "                                                                 \n",
            " reshape_1 (Reshape)         (None, 64, 64, 3)         0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 37761024 (144.05 MB)\n",
            "Trainable params: 37761024 (144.05 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create a random array with number from 0 to 255 of shape (1024,1024,3) and forward propogate throught disc\n",
        "\n",
        "rand_arr = np.random.randint(0,1,(64,64,3))\n",
        "# rand_arr = rand_arr.reshape((11024,1024))\n",
        "disc.predict(np.array([rand_arr]))\n"
      ],
      "metadata": {
        "id": "g4qpUWwy4rIH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b9aa1bb-4520-434e-fe2e-f00751639c6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 4s 4s/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.5]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random as rd\n",
        "import time\n",
        "\n",
        "def pick_box(img:np.ndarray,box_size:int):\n",
        "    img_shape = img.shape\n",
        "    x_max, y_max = img_shape[0] - box_size, img_shape[1] - box_size\n",
        "    x, y = rd.randint(0,x_max), rd.randint(0,y_max)\n",
        "    box = img[x:x+box_size,y:y+box_size,:] #check shape of box\n",
        "    assert box.shape == (box_size,box_size,3)\n",
        "    return box\n",
        "\n",
        "def make_real_batch_arr(img_names:list):\n",
        "    boxes_lst = []\n",
        "    for img_num in img_names:\n",
        "        img_hr = get_img_arr(\"/content/gdrive/MyDrive/00000/\"+img_num+\".png\") #replace with location of data\n",
        "        box = pick_box(img_hr,HR_shape[0])\n",
        "        boxes_lst.append(box)\n",
        "    boxes_arr = np.array(boxes_lst)\n",
        "    return boxes_arr/255\n",
        "\n",
        "def gen_input_batch_arr(img_names:list):\n",
        "    boxes_lst = []\n",
        "    for img_num in img_names:\n",
        "        img_lr = get_img_arr(\"/content/gdrive/MyDrive/lr_imgs/\"+img_num+\"_lr.png\") #replace with location of LR imgs\n",
        "        box = pick_box(img_lr,LR_shape[0])\n",
        "        boxes_lst.append(box)\n",
        "    boxes_arr = np.array(boxes_lst)\n",
        "    return boxes_arr/255\n",
        "\n",
        "def make_name_batches(img_names:list,batch_size:int):\n",
        "    batches = []\n",
        "    for i in range(len(img_names)//batch_size):\n",
        "        batches.append(img_names[i*batch_size:(i+1)*batch_size])\n",
        "    return batches\n",
        "\n",
        "\n",
        "# arr = make_real_batch_arr(['00000','00001','00002'])\n",
        "# arr.shape\n",
        "# box = pick_box(img0,32)\n",
        "# box.shape\n"
      ],
      "metadata": {
        "id": "mqH_9sQvLvHp"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start = time.time()\n",
        "\n",
        "no_of_epochs = 10\n",
        "batch_size = 100\n",
        "\n",
        "real = np.ones((batch_size,1))\n",
        "fake = np.zeros((batch_size,1))\n",
        "\n",
        "\n",
        "img_names = [str(i).zfill(5) for i in range(900)]\n",
        "\n",
        "for epoch in range(1,no_of_epochs+1):\n",
        "    print(\"Epoch: \",epoch)\n",
        "    rd.shuffle(img_names)\n",
        "    batches = make_name_batches(img_names,batch_size)\n",
        "    for batch in batches:\n",
        "        real_batch_arr = make_real_batch_arr(batch)\n",
        "        gen_input_arr = gen_input_batch_arr(batch)\n",
        "        fake_batch_arr = gen.predict(gen_input_arr)\n",
        "        #disc training\n",
        "        weights = disc.get_weights()[0]\n",
        "        disc.train_on_batch(real_batch_arr,real)\n",
        "        disc.train_on_batch(fake_batch_arr,fake)\n",
        "        assert np.any(disc.get_weights()[0] != weights)\n",
        "\n",
        "        #combined gan training\n",
        "        combined_gan.train_on_batch(gen_input_arr,real)\n",
        "\n",
        "end = time.time()\n",
        "print(\"Time Taken: \",end-start)\n",
        "combined_gan.save(\"/content/gdrive/MyDrive/model/combined_gan\") # replace with desired location to save model\n",
        "gen.save(\"/content/gdrive/MyDrive/model/generator\") #replace with desired location to save model\n",
        "disc.save(\"/content/gdrive/MyDrive/model/discriminator\") #replace with desired location to save model\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kOEGZTY7Ue2P",
        "outputId": "59a5c8c8-0f4d-4c71-d81e-13ab37598ed3"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:  1\n",
            "4/4 [==============================] - 0s 49ms/step\n",
            "4/4 [==============================] - 0s 33ms/step\n",
            "4/4 [==============================] - 0s 46ms/step\n",
            "4/4 [==============================] - 0s 31ms/step\n",
            "4/4 [==============================] - 0s 44ms/step\n",
            "4/4 [==============================] - 0s 33ms/step\n",
            "4/4 [==============================] - 0s 30ms/step\n",
            "4/4 [==============================] - 0s 32ms/step\n",
            "4/4 [==============================] - 0s 31ms/step\n",
            "Epoch:  2\n",
            "4/4 [==============================] - 0s 48ms/step\n",
            "4/4 [==============================] - 0s 32ms/step\n",
            "4/4 [==============================] - 0s 31ms/step\n",
            "4/4 [==============================] - 0s 34ms/step\n",
            "4/4 [==============================] - 0s 31ms/step\n",
            "4/4 [==============================] - 0s 46ms/step\n",
            "4/4 [==============================] - 0s 31ms/step\n",
            "4/4 [==============================] - 0s 30ms/step\n",
            "4/4 [==============================] - 0s 34ms/step\n",
            "Epoch:  3\n",
            "4/4 [==============================] - 0s 31ms/step\n",
            "4/4 [==============================] - 0s 50ms/step\n",
            "4/4 [==============================] - 0s 33ms/step\n",
            "4/4 [==============================] - 0s 34ms/step\n",
            "4/4 [==============================] - 0s 32ms/step\n",
            "4/4 [==============================] - 0s 34ms/step\n",
            "4/4 [==============================] - 0s 50ms/step\n",
            "4/4 [==============================] - 0s 31ms/step\n",
            "4/4 [==============================] - 0s 33ms/step\n",
            "Epoch:  4\n",
            "4/4 [==============================] - 0s 63ms/step\n",
            "4/4 [==============================] - 0s 31ms/step\n",
            "4/4 [==============================] - 0s 47ms/step\n",
            "4/4 [==============================] - 0s 31ms/step\n",
            "4/4 [==============================] - 0s 48ms/step\n",
            "4/4 [==============================] - 0s 31ms/step\n",
            "4/4 [==============================] - 0s 33ms/step\n",
            "4/4 [==============================] - 0s 45ms/step\n",
            "4/4 [==============================] - 0s 32ms/step\n",
            "Epoch:  5\n",
            "4/4 [==============================] - 0s 49ms/step\n",
            "4/4 [==============================] - 0s 33ms/step\n",
            "4/4 [==============================] - 0s 33ms/step\n",
            "4/4 [==============================] - 0s 46ms/step\n",
            "4/4 [==============================] - 0s 32ms/step\n",
            "4/4 [==============================] - 0s 46ms/step\n",
            "4/4 [==============================] - 0s 31ms/step\n",
            "4/4 [==============================] - 0s 32ms/step\n",
            "4/4 [==============================] - 0s 47ms/step\n",
            "Epoch:  6\n",
            "4/4 [==============================] - 0s 32ms/step\n",
            "4/4 [==============================] - 0s 48ms/step\n",
            "4/4 [==============================] - 0s 34ms/step\n",
            "4/4 [==============================] - 0s 31ms/step\n",
            "4/4 [==============================] - 0s 43ms/step\n",
            "4/4 [==============================] - 0s 31ms/step\n",
            "4/4 [==============================] - 0s 49ms/step\n",
            "4/4 [==============================] - 0s 31ms/step\n",
            "4/4 [==============================] - 0s 34ms/step\n",
            "Epoch:  7\n",
            "4/4 [==============================] - 0s 49ms/step\n",
            "4/4 [==============================] - 0s 33ms/step\n",
            "4/4 [==============================] - 0s 44ms/step\n",
            "4/4 [==============================] - 0s 31ms/step\n",
            "4/4 [==============================] - 0s 34ms/step\n",
            "4/4 [==============================] - 0s 50ms/step\n",
            "4/4 [==============================] - 0s 31ms/step\n",
            "4/4 [==============================] - 0s 48ms/step\n",
            "4/4 [==============================] - 0s 32ms/step\n",
            "Epoch:  8\n",
            "4/4 [==============================] - 0s 31ms/step\n",
            "4/4 [==============================] - 0s 46ms/step\n",
            "4/4 [==============================] - 0s 32ms/step\n",
            "4/4 [==============================] - 0s 46ms/step\n",
            "4/4 [==============================] - 0s 32ms/step\n",
            "4/4 [==============================] - 0s 30ms/step\n",
            "4/4 [==============================] - 0s 46ms/step\n",
            "4/4 [==============================] - 0s 31ms/step\n",
            "4/4 [==============================] - 0s 47ms/step\n",
            "Epoch:  9\n",
            "4/4 [==============================] - 0s 32ms/step\n",
            "4/4 [==============================] - 0s 32ms/step\n",
            "4/4 [==============================] - 0s 46ms/step\n",
            "4/4 [==============================] - 0s 32ms/step\n",
            "4/4 [==============================] - 0s 45ms/step\n",
            "4/4 [==============================] - 0s 31ms/step\n",
            "4/4 [==============================] - 0s 32ms/step\n",
            "4/4 [==============================] - 0s 46ms/step\n",
            "4/4 [==============================] - 0s 32ms/step\n",
            "Epoch:  10\n",
            "4/4 [==============================] - 0s 45ms/step\n",
            "4/4 [==============================] - 0s 30ms/step\n",
            "4/4 [==============================] - 0s 31ms/step\n",
            "4/4 [==============================] - 0s 44ms/step\n",
            "4/4 [==============================] - 0s 32ms/step\n",
            "4/4 [==============================] - 0s 30ms/step\n",
            "4/4 [==============================] - 0s 33ms/step\n",
            "4/4 [==============================] - 0s 31ms/step\n",
            "4/4 [==============================] - 0s 46ms/step\n",
            "Time Taken:  516.0041506290436\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#get the saved models back as the same variable name\n",
        "\n",
        "combined_gan = ke.models.load_model(\"/content/gdrive/MyDrive/model/combined_gan\") #replace with location of model\n",
        "gen = ke.models.load_model(\"/content/gdrive/MyDrive/model/generator\") #replace with location of model\n",
        "disc = ke.models.load_model(\"/content/gdrive/MyDrive/model/discriminator\") #replace with location of model\n"
      ],
      "metadata": {
        "id": "ZgqErAepPH6a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prediction\n",
        "\n",
        "def enhance(generator,img_lr:np.ndarray):\n",
        "    img_shape = (1024,1024,3)\n",
        "    img_hr_arr = np.zeros(img_shape)\n",
        "    box_size = LR_shape[0]\n",
        "    input_boxes = []\n",
        "    for x in range(0,512,box_size):\n",
        "        for y in range(0,512,box_size):\n",
        "            lr_box = img_lr[x:x+box_size,y:y+box_size,:]\n",
        "            input_boxes.append(lr_box)\n",
        "    input_arr = np.array(input_boxes)\n",
        "    output_arr = generator.predict(input_arr)\n",
        "    n = 0\n",
        "    for x in range(0,1024,s*box_size):\n",
        "        for y in range(0,1024,s*box_size):\n",
        "            img_hr_arr[x:x+s*box_size,y:y+s*box_size,:] = output_arr[n]\n",
        "            n += 1\n",
        "    img_hr_arr = 255*img_hr_arr\n",
        "    img_hr = Image.fromarray(img_hr_arr.astype(np.uint8))\n",
        "    return img_hr\n"
      ],
      "metadata": {
        "id": "zvj-M4h_fm46"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_num = '00000'\n",
        "img_lr = get_img_arr(\"/content/gdrive/MyDrive/lr_imgs/\"+img_num+\"_lr.png\") #replace with location of LR imgs\n",
        "img_hr = enhance(gen,img_lr)\n",
        "img_hr.save(\"test_enhanced_img.png\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dhgIiDCvI2ed",
        "outputId": "1f83fd40-c3e6-4ccc-8635-84648ef6d589"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8/8 [==============================] - 1s 60ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "n35AYshuJS1S"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}